# Ambiente PostgreSQL automatizado


Este projeto levanta um ambiente completo com:

- PostgreSQL 17 com suporte a SSH
- Servidor de backup em Ubuntu com **pgBackRest**
- Exportador de m√©tricas **postgres_exporter**
- Monitoramento via **Prometheus**
- Dashboard com **Grafana**
- ETL com **Airflow + dbt**
- EL com **PGLoader**
- PostgreSQL 17 servindo como DW

> O projeto utiliza **Docker Compose** para facilitar o provisionamento e gerenciamento dos servi√ßos.

---

## üöÄ Servi√ßos inclu√≠dos

| Servi√ßo              | Descri√ß√£o                                                    |
|----------------------|--------------------------------------------------------------|
| `maquina1`           | PostgreSQL 17 com SSH habilitado                             |
| `maquina2`           | Ubuntu com pgBackRest configurado para backups remotos       |
| `postgres_exporter`  | Exportador de m√©tricas para o Prometheus                     |
| `prometheus`         | Coletor de m√©tricas                                          |
| `grafana`            | Dashboard para visualiza√ß√£o dos dados                        |

---

## üìú Pr√©-requisitos

- [Docker](https://www.docker.com/)
- [Docker Compose](https://docs.docker.com/compose/)

---

## üîß Comandos dispon√≠veis (`run.sh`)

### `./run.sh build`

O servi√ßo deve ser buildado dessa forma, caso contr√°rio o airflow, n√£o ir√° funcionar. O bash exporta uma vari√°vel que √© utilizada por ele.
Faz o build das imagens com cache desabilitado e limite de mem√≥ria:

```bash
docker-compose build --no-cache --memory 4g --progress=plain
```

---

### `./run.sh up`

Sobe todos os containers em segundo plano (`-d`):

```bash
docker-compose up -d
```

---

### `./run.sh stop` ou `./run.sh drop`

Derruba todos os containers:

```bash
docker-compose down
```

---

### `./run.sh restart`

Reinicia todos os servi√ßos:

```bash
docker-compose down && docker-compose up -d
```

---

### `./run.sh drop_hard`

Derruba os containers, remove imagens, volumes e dados persistidos localmente:

```bash
docker-compose down --volumes --remove-orphans --rmi all
docker builder prune --all --force
sudo rm -rf ./maquina1/data ./maquina1/log
sudo rm -rf ./maquina2/data ./maquina2/log
```

‚ö†Ô∏è **Aten√ß√£o:** este comando apaga os dados da base e do backup.

---

### `./run.sh cpKeys`

Gera e configura chaves SSH entre `maquina1` e `maquina2` para permitir backups via `pgBackRest`.

---

### `./run.sh bashMaquina1`

Abre um shell interativo no container `maquina1` como usu√°rio `postgres`.

---

### `./run.sh bashMaquina2`

Abre um shell interativo no container `maquina2` como usu√°rio `postgres`.

---

## üìà Monitoramento

* A exporta√ß√£o de m√©tricas do PostgreSQL √© feita via [`postgres_exporter`](https://github.com/prometheus-community/postgres_exporter).
* O Prometheus coleta e armazena as m√©tricas.
* O Grafana exibe as m√©tricas em dashboards interativos.

---

## üíæ Backup com pgBackRest

* O `pgBackRest` √© instalado no container `maquina2` (Ubuntu).
* A comunica√ß√£o entre os servidores √© feita via SSH.
* O script `cpKeys` cuida da gera√ß√£o e troca de chaves p√∫blicas.

---

## üìÇ Processo de backup

1. Execute:

   ```bash
   ./run.sh cpKeys
   ```

   para configurar a comunica√ß√£o SSH entre as m√°quinas.

2. Execute:

   ```bash
   docker exec -u postgres maquina1 pgbackrest --stanza=maquina1 stanza-create
   ```

   para criar pasta dedicada para o backup no servidor de backup `maquina2`.


3. Execute:

   ```bash
   docker exec -u postgres maquina1 pgbackrest --stanza=maquina1 check
   ```

   para testar a comunica√ß√£o SSH entre as m√°quinas.

4. Execute:

   ```bash
   docker exec -u postgres maquina1 pgbackrest --stanza=maquina1 --type=full backup
   ```

   para realizar o primeiro backup completo.

5. Execute:

   ```bash
   docker exec -u postgres maquina1 pgbackrest --stanza=maquina1 info
   ```

   para verificar o status do backup.

6. Execute:

   ```bash
   docker exec -u postgres maquina1 pg_ctl stop -D /var/lib/postgresql/data/pgdata
   docker exec -u root maquina1 rm -rf /var/lib/postgresql/data/pgdata
   docker exec -u root maquina1 ls /var/lib/postgresql/data/pgdata   --> o caminho n√£o pode existir, deletamos todos o banco
   docker exec -u postgres maquina1 pgbackrest --stanza=maquina1 --type=time --target="2025-07-07 18:50:47-03" restore
   docker exec -u root maquina1 chown -R postgres:postgres /var/lib/postgresql/data/pgdata
   docker exec -u root maquina1 chmod 750 /var/lib/postgresql/data/pgdata
   bash run.sh restart
   ```

   para realizar o restore do backup.

   ‚ö†Ô∏è **Aten√ß√£o:** Para ver os arquivos √© necess√°rios executar o comando para ter permiss√£o. sudo chmod 777 ./ -R

8. Verifique os logs do PostgreSQL se houver falhas no `pgBackRest`:

   ```bash
   docker exec maquina1 tail -f /var/lib/postgresql/log/postgresql.log
   ```

   ou acesse direto pelo na pasta `maquina1/log`

## üßë‚Äçüíª Processo de monitoramento

1. Acesse o Grafana em: [http://localhost:3000](http://localhost:4000)

   * Usu√°rio padr√£o: `admin`
   * Senha padr√£o: `senha`

   exemplo de dash: https://grafana.com/grafana/dashboards/9628-postgresql-database/


## üìÇ‚û°Ô∏èüì§ Processo de carga de dados pelo pgloader

1. Lembre-se de colocar o arquivo .sqlite que ser√° importado dentro da pasta pgloader

   ```bash
   cd pglaoder
   bash run.sh
   ```

## üì• ‚û°Ô∏è üîÑ ‚û°Ô∏è üì§ Processo de ETL com Airflow + dbt

O Airflow j√° est√° configurado e os volumes dentro dele e do dbt j√° foram criados, portanto, n√£o precisa reiniciar o container para modificar arquivos de DAGs e model do DBT.

1. Suas DAGs s√£o o processos do Airflow que ir√£o executar seu ETL.

2. Os diret√≥rios das DAGs j√° foram configurados e a interface do Airflow pode ser acessada em http://localhost:8080/ utilizar a senha "airflow" e usu√°rio "airflow". Uma DAG que roda o batch do dbt j√° ir√° estar dispon√≠vel. Utilizem a interface para rodar seus DAGs.

3. O DBT ir√° executar os arquivos de SQL que estiverem dentro da pasta models. Criei 2 schemas iniciais: staging, intermediate e mart. Usem eles para executarem diferentes transforma√ß√µes com o dbt para tranformar as tabelas at√© chegar a forma√ß√£o do dw.

4. Uma model de exemplo j√° foi criada e j√° est√° levando as informa√ß√µes do container da maquina1 para o dw.

5. Criem os arquivo de sql necess√°rios para execu√ß√£o de processo de etl.

6. Comando para rodar o dbt manualmente. Este j√° est√° dentro da dag do airflow:

   ```bash
   cd /opt/airflow/dbt && dbt run --target destination --profiles-dir /opt/airflow/dbt
   ```